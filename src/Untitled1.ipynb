{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-16e55eb9d473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msecrets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Copyright (c) 2020. Asutosh Nayak (nayak.asutosh@ymail.com)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "\n",
    "import os\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tqdm.auto import tqdm\n",
    "from logger import Logger\n",
    "from secrets import api_key\n",
    "from utils import *\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, company_code, data_path='./stock_history', output_path='./outputs', strategy_type='original',\n",
    "                 update=False, logger: Logger = None):\n",
    "        self.company_code = company_code\n",
    "        self.strategy_type = strategy_type\n",
    "        self.data_path = data_path\n",
    "        self.logger = logger\n",
    "        self.BASE_URL = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED\" \\\n",
    "                        \"&outputsize=full&apikey=\" + api_key + \"&datatype=csv&symbol=\"  # api key from alpha vantage service\n",
    "        self.output_path = output_path\n",
    "        self.start_col = 'open'\n",
    "        self.end_col = 'eom_26'\n",
    "        self.update = update\n",
    "        self.download_stock_data()\n",
    "        self.df = self.create_features()\n",
    "        self.feat_idx = self.feature_selection()\n",
    "        self.one_hot_enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "        self.one_hot_enc.fit(self.df['labels'].values.reshape(-1, 1))\n",
    "        self.batch_start_date = self.df.head(1).iloc[0][\"timestamp\"]\n",
    "        self.test_duration_years = 1\n",
    "        self.logger.append_log(\"{} has data for {} to {}\".format(data_path, self.batch_start_date,\n",
    "                                                                 self.df.tail(1).iloc[0]['timestamp']))\n",
    "\n",
    "    def log(self, text):\n",
    "        if self.logger:\n",
    "            self.logger.append_log(text)\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "    def download_stock_data(self):\n",
    "        path_to_company_data = self.data_path\n",
    "        print(\"path to company data:\", path_to_company_data)\n",
    "        parent_path = os.sep.join(path_to_company_data.split(os.sep)[:-1])\n",
    "        if not os.path.exists(parent_path):\n",
    "            os.makedirs(parent_path)\n",
    "            print(\"Company Directory created\", parent_path)\n",
    "\n",
    "        if not os.path.exists(path_to_company_data):\n",
    "            self.log(\"Downloading \" + self.company_code + \" data\")\n",
    "            download_save(self.BASE_URL + self.company_code, path_to_company_data, self.logger)\n",
    "        else:\n",
    "            self.log(\"Data for \" + self.company_code + \" ready to use\")\n",
    "\n",
    "    def calculate_technical_indicators(self, df, col_name, intervals):\n",
    "        # get_RSI(df, col_name, intervals)  # faster but non-smoothed RSI\n",
    "        get_RSI_smooth(df, col_name, intervals)  # momentum\n",
    "        get_williamR(df, col_name, intervals)  # momentum\n",
    "        get_mfi(df, intervals)  # momentum\n",
    "        # get_MACD(df, col_name, intervals)  # momentum, ready to use +3\n",
    "        # get_PPO(df, col_name, intervals)  # momentum, ready to use +1\n",
    "        get_ROC(df, col_name, intervals)  # momentum\n",
    "        get_CMF(df, col_name, intervals)  # momentum, volume EMA\n",
    "        get_CMO(df, col_name, intervals)  # momentum\n",
    "        get_SMA(df, col_name, intervals)\n",
    "        get_SMA(df, 'open', intervals)\n",
    "        get_EMA(df, col_name, intervals)\n",
    "        get_WMA(df, col_name, intervals)\n",
    "        get_HMA(df, col_name, intervals)\n",
    "        get_TRIX(df, col_name, intervals)  # trend\n",
    "        get_CCI(df, col_name, intervals)  # trend\n",
    "        get_DPO(df, col_name, intervals)  # Trend oscillator\n",
    "        get_kst(df, col_name, intervals)  # Trend\n",
    "        get_DMI(df, col_name, intervals)  # trend\n",
    "        get_BB_MAV(df, col_name, intervals)  # volatility\n",
    "        # get_PSI(df, col_name, intervals)  # can't find formula\n",
    "        get_force_index(df, intervals)  # volume\n",
    "        get_kdjk_rsv(df, intervals)  # ready to use, +2*len(intervals), 2 rows\n",
    "        get_EOM(df, col_name, intervals)  # volume momentum\n",
    "        get_volume_delta(df)  # volume +1\n",
    "        get_IBR(df)  # ready to use +1\n",
    "\n",
    "    def create_labels(self, df, col_name, window_size=11):\n",
    "        \"\"\"\n",
    "        Data is labeled as per the logic in research paper\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "\n",
    "        returns : numpy array with integer codes for labels with\n",
    "                  size = total-(window_size)+1\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating label with original paper strategy\")\n",
    "        row_counter = 0\n",
    "        total_rows = len(df)\n",
    "        labels = np.zeros(total_rows)\n",
    "        labels[:] = np.nan\n",
    "        print(\"Calculating labels\")\n",
    "        pbar = tqdm(total=total_rows)\n",
    "\n",
    "        while row_counter < total_rows:\n",
    "            if row_counter >= window_size - 1:\n",
    "                window_begin = row_counter - (window_size - 1)\n",
    "                window_end = row_counter\n",
    "                window_middle = (window_begin + window_end) / 2\n",
    "\n",
    "                min_ = np.inf\n",
    "                min_index = -1\n",
    "                max_ = -np.inf\n",
    "                max_index = -1\n",
    "                for i in range(window_begin, window_end + 1):\n",
    "                    price = df.iloc[i][col_name]\n",
    "                    if price < min_:\n",
    "                        min_ = price\n",
    "                        min_index = i\n",
    "                    if price > max_:\n",
    "                        max_ = price\n",
    "                        max_index = i\n",
    "\n",
    "                if max_index == window_middle:\n",
    "                    labels[window_middle] = 0\n",
    "                elif min_index == window_middle:\n",
    "                    labels[window_middle] = 1\n",
    "                else:\n",
    "                    labels[window_middle] = 2\n",
    "\n",
    "            row_counter = row_counter + 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        return labels\n",
    "\n",
    "    def create_labels_price_rise(self, df, col_name):\n",
    "        \"\"\"\n",
    "        labels data based on price rise on next day\n",
    "          next_day - prev_day\n",
    "        ((s - s.shift()) > 0).astype(np.int)\n",
    "        \"\"\"\n",
    "\n",
    "        df[\"labels\"] = ((df[col_name] - df[col_name].shift()) > 0).astype(np.int)\n",
    "        df = df[1:]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def create_label_mean_reversion(self, df, col_name):\n",
    "        \"\"\"\n",
    "        strategy as described at \"https://decodingmarkets.com/mean-reversion-trading-strategy\"\n",
    "\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "\n",
    "        returns : numpy array with integer codes for labels\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating labels with mean mean-reversion-trading-strategy\")\n",
    "        get_RSI_smooth(df, col_name, [3])  # new column 'rsi_3' added to df\n",
    "        rsi_3_series = df['rsi_3']\n",
    "        ibr = get_IBR(df)\n",
    "        total_rows = len(df)\n",
    "        labels = np.zeros(total_rows)\n",
    "        labels[:] = np.nan\n",
    "        count = 0\n",
    "        for i, rsi_3 in enumerate(rsi_3_series):\n",
    "            if rsi_3 < 15:  # buy\n",
    "                count = count + 1\n",
    "\n",
    "                if 3 <= count < 8 and ibr.iloc[i] < 0.2:  # TODO implement upto 5 BUYS\n",
    "                    labels[i] = 1\n",
    "\n",
    "                if count >= 8:\n",
    "                    count == 0\n",
    "            elif ibr.iloc[i] > 0.7:  # sell\n",
    "                labels[i] = 0\n",
    "            else:\n",
    "                labels[i] = 2\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def create_label_short_long_ma_crossover(self, df, col_name, short, long):\n",
    "        \"\"\"\n",
    "        if short = 30 and long = 90,\n",
    "        Buy when 30 day MA < 90 day MA\n",
    "        Sell when 30 day MA > 90 day MA\n",
    "\n",
    "        Label code : BUY => 1, SELL => 0, HOLD => 2\n",
    "\n",
    "        params :\n",
    "            df => Dataframe with data\n",
    "            col_name => name of column which should be used to determine strategy\n",
    "\n",
    "        returns : numpy array with integer codes for labels\n",
    "        \"\"\"\n",
    "\n",
    "        self.log(\"creating label with {}_{}_ma\".format(short, long))\n",
    "\n",
    "        def detect_crossover(diff_prev, diff):\n",
    "            if diff_prev >= 0 > diff:\n",
    "                # buy\n",
    "                return 1\n",
    "            elif diff_prev <= 0 < diff:\n",
    "                return 0\n",
    "            else:\n",
    "                return 2\n",
    "\n",
    "        get_SMA(df, 'close', [short, long])\n",
    "        labels = np.zeros((len(df)))\n",
    "        labels[:] = np.nan\n",
    "        diff = df['close_sma_' + str(short)] - df['close_sma_' + str(long)]\n",
    "        diff_prev = diff.shift()\n",
    "        df['diff_prev'] = diff_prev\n",
    "        df['diff'] = diff\n",
    "\n",
    "        res = df.apply(lambda row: detect_crossover(row['diff_prev'], row['diff']), axis=1)\n",
    "        print(\"labels count\", np.unique(res, return_counts=True))\n",
    "        df.drop(columns=['diff_prev', 'diff'], inplace=True)\n",
    "        return res\n",
    "\n",
    "    def create_features(self):\n",
    "        if not os.path.exists(os.path.join(self.output_path, \"df_\" + self.company_code+\".csv\")) or self.update:\n",
    "            df = pd.read_csv(self.data_path, engine='python')\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.sort_values('timestamp', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            intervals = range(6, 27)  # 21\n",
    "            self.calculate_technical_indicators(df, 'close', intervals)\n",
    "            self.log(\"Saving dataframe...\")\n",
    "            df.to_csv(os.path.join(self.output_path, \"df_\" + self.company_code+\".csv\"), index=False)\n",
    "        else:\n",
    "            self.log(\"Technical indicators already calculated. Loading...\")\n",
    "            df = pd.read_csv(os.path.join(self.output_path, \"df_\" + self.company_code+\".csv\"))\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.sort_values('timestamp', inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            # pickle.load(open(os.path.join(self.output_path, \"df_\" + self.company_code), \"rb\"))\n",
    "\n",
    "        prev_len = len(df)\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        self.logger.append_log(\"Dropped {0} nan rows before label calculation\".format(prev_len - len(df)))\n",
    "\n",
    "        if 'labels' not in df.columns or self.update:\n",
    "            if re.match(r\"\\d+_\\d+_ma\", self.strategy_type):\n",
    "                short = self.strategy_type.split('_')[0]\n",
    "                long = self.strategy_type.split('_')[1]\n",
    "                df['labels'] = self.create_label_short_long_ma_crossover(df, 'close', short, long)\n",
    "            else:\n",
    "                df['labels'] = self.create_labels(df, 'close')\n",
    "\n",
    "            prev_len = len(df)\n",
    "            df.dropna(inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            self.logger.append_log(\"Dropped {0} nan rows after label calculation\".format(prev_len - len(df)))\n",
    "            df.drop(columns=['dividend_amount', 'split_coefficient'], inplace=True)\n",
    "            df.to_csv(os.path.join(self.output_path, \"df_\" + self.company_code + \".csv\"), index=False)\n",
    "        else:\n",
    "            print(\"labels already calculated\")\n",
    "\n",
    "        # pickle.dump(df, open(os.path.join(self.output_path, \"df_\" + self.company_code), 'wb'))\n",
    "        # console_pretty_print_df(df.head())\n",
    "        self.log(\"Number of Technical indicator columns for train/test are {}\".format(len(list(df.columns)[7:])))\n",
    "        return df\n",
    "\n",
    "    def feature_selection(self):\n",
    "        df_batch = self.df_by_date(None, 10)\n",
    "        list_features = list(df_batch.loc[:, self.start_col:self.end_col].columns)\n",
    "        mm_scaler = MinMaxScaler(feature_range=(0, 1))  # or StandardScaler?\n",
    "        x_train = mm_scaler.fit_transform(df_batch.loc[:, self.start_col:self.end_col].values)\n",
    "        y_train = df_batch['labels'].values\n",
    "        num_features = 225  # should be a perfect square\n",
    "        topk = 350\n",
    "        select_k_best = SelectKBest(f_classif, k=topk)\n",
    "        select_k_best.fit(x_train, y_train)\n",
    "        selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "\n",
    "        select_k_best = SelectKBest(mutual_info_classif, k=topk)\n",
    "        select_k_best.fit(x_train, y_train)\n",
    "        selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
    "\n",
    "        common = list(set(selected_features_anova).intersection(selected_features_mic))\n",
    "        self.log(\"common selected featues:\" + str(len(common)) + \", \" + str(common))\n",
    "        if len(common) < num_features:\n",
    "            raise Exception(\n",
    "                'number of common features found {} < {} required features. Increase \"topK\"'.format(len(common),\n",
    "                                                                                                    num_features))\n",
    "        feat_idx = []\n",
    "        for c in common:\n",
    "            feat_idx.append(list_features.index(c))\n",
    "        feat_idx = sorted(feat_idx[0:225])\n",
    "        self.log(str(feat_idx))\n",
    "        return feat_idx\n",
    "\n",
    "    def df_by_date(self, start_date=None, years=5):\n",
    "        if not start_date:\n",
    "            start_date = self.df.head(1).iloc[0][\"timestamp\"]\n",
    "\n",
    "        end_date = start_date + pd.offsets.DateOffset(years=years)\n",
    "        df_batch = self.df[(self.df[\"timestamp\"] >= start_date) & (self.df[\"timestamp\"] <= end_date)]\n",
    "        return df_batch\n",
    "\n",
    "    def get_data(self, start_date=None, years=5):\n",
    "        df_batch = self.df_by_date(start_date, years)\n",
    "        x = df_batch.loc[:, self.start_col:self.end_col].values\n",
    "        x = x[:, self.feat_idx]\n",
    "        mm_scaler = MinMaxScaler(feature_range=(0, 1))  # or StandardScaler?\n",
    "        x = mm_scaler.fit_transform(x)\n",
    "        dim = int(np.sqrt(x.shape[1]))\n",
    "        x = reshape_as_image(x, dim, dim)\n",
    "        x = np.stack((x,) * 3, axis=-1)\n",
    "\n",
    "        y = df_batch['labels'].values\n",
    "        sample_weights = self.get_sample_weights(y)\n",
    "        y = self.one_hot_enc.transform(y.reshape(-1, 1))\n",
    "\n",
    "        return x, y, df_batch, sample_weights\n",
    "\n",
    "    def get_sample_weights(self, y):\n",
    "        \"\"\"\n",
    "        calculate the sample weights based on class weights. Used for models with\n",
    "        imbalanced data and one hot encoding prediction.\n",
    "\n",
    "        params:\n",
    "            y: class labels as integers\n",
    "        \"\"\"\n",
    "\n",
    "        y = y.astype(int)  # compute_class_weight needs int labels\n",
    "        class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "        print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
    "        print(\"value_counts\", np.unique(y, return_counts=True))\n",
    "        sample_weights = y.copy().astype(float)\n",
    "        for i in np.unique(y):\n",
    "            sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
    "            # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
    "\n",
    "        return sample_weights\n",
    "\n",
    "    def get_rolling_data_next(self, start_date=None, window_size_yrs=6, cross_val_split=0.2):\n",
    "        if not start_date:\n",
    "            start_date = self.batch_start_date\n",
    "\n",
    "        x_train, y_train, df_batch_train, sample_weights = self.get_data(start_date, window_size_yrs)\n",
    "        train_end_date = df_batch_train.tail(1).iloc[0][\"timestamp\"]\n",
    "        test_start_date = train_end_date + pd.offsets.DateOffset(days=1)\n",
    "        test_end_date = test_start_date + pd.offsets.DateOffset(years=self.test_duration_years)\n",
    "        x_test, y_test, df_batch_test, _ = self.get_data(test_start_date, self.test_duration_years)\n",
    "        x_train, x_cv, y_train, y_cv, sample_weights, _ = train_test_split(x_train, y_train, sample_weights,\n",
    "                                                                           train_size=1 - cross_val_split,\n",
    "                                                                           test_size=cross_val_split,\n",
    "                                                                           random_state=2, shuffle=True,\n",
    "                                                                           stratify=y_train)\n",
    "        self.logger.append_log(\"data generated: train duration={}-{}, test_duration={}-{}, size={}, {}, {}\".format(\n",
    "            self.batch_start_date, train_end_date, test_start_date, test_end_date, x_train.shape, x_cv.shape,\n",
    "            x_test.shape))\n",
    "\n",
    "        self.batch_start_date = self.batch_start_date + pd.offsets.DateOffset(years=1)\n",
    "        is_last_batch = False\n",
    "        if (self.df.tail(1).iloc[0][\"timestamp\"] - test_end_date).days < 180:  # 6 months\n",
    "            is_last_batch = True\n",
    "        return x_train, y_train, x_cv, y_cv, x_test, y_test, df_batch_train, df_batch_test, \\\n",
    "               sample_weights, is_last_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
